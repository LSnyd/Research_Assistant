{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import find_max_length\n",
    "from datasets import load_dataset, dataset_dict, DatasetDict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and split Dataset from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/lisa/.cache/huggingface/datasets/CShorten___csv/CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    }
   ],
   "source": [
    "arxiv_dataset = (load_dataset(path=\"CShorten/ML-ArXiv-Papers\", split='train').train_test_split(train_size=90000, test_size=10000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_dataset = DatasetDict({\n",
    "    'train': arxiv_dataset['train'],\n",
    "    'validation': arxiv_dataset['test']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Unnamed: 0.1', 'Unnamed: 0', 'title', 'abstract'],\n",
      "    num_rows: 90000\n",
      "}) Dataset({\n",
      "    features: ['Unnamed: 0.1', 'Unnamed: 0', 'title', 'abstract'],\n",
      "    num_rows: 10000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(arxiv_dataset['train'],\n",
    "arxiv_dataset['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0.1': 3169,\n",
       " 'Unnamed: 0': None,\n",
       " 'title': 'FedEntropy: Efficient Device Grouping for Federated Learning Using Maximum Entropy Judgment',\n",
       " 'abstract': 'Along with the popularity of Artificial Intelligence (AI) and\\nInternet-of-Things (IoT), Federated Learning (FL) has attracted steadily\\nincreasing attentions as a promising distributed machine learning paradigm,\\nwhich enables the training of a central model on for numerous decentralized\\ndevices without exposing their privacy. However, due to the biased data\\ndistributions on involved devices, FL inherently suffers from low\\nclassification accuracy in non-IID scenarios. Although various device grouping\\nmethod have been proposed to address this problem, most of them neglect both i)\\ndistinct data distribution characteristics of heterogeneous devices, and ii)\\ncontributions and hazards of local models, which are extremely important in\\ndetermining the quality of global model aggregation. In this paper, we present\\nan effective FL method named FedEntropy with a novel dynamic device grouping\\nscheme, which makes full use of the above two factors based on our proposed\\nmaximum entropy judgement heuristic.Unlike existing FL methods that directly\\naggregate local models returned from all the selected devices, in one FL round\\nFedEntropy firstly makes a judgement based on the pre-collected soft labels of\\nselected devices and then only aggregates the local models that can maximize\\nthe overall entropy of these soft labels. Without collecting local models that\\nare harmful for aggregation, FedEntropy can effectively improve global model\\naccuracy while reducing the overall communication overhead. Comprehensive\\nexperimental results on well-known benchmarks show that, FedEntropy not only\\noutperforms state-of-the-art FL methods in terms of model accuracy and\\ncommunication overhead, but also can be integrated into them to enhance their\\nclassification performance.',\n",
       " 'abstracttitle': '<|endoftext|> Along with the popularity of Artificial Intelligence (AI) and Internet-of-Things (IoT), Federated Learning (FL) has attracted steadily increasing attentions as a promising distributed machine learning paradigm, which enables the training of a central model on for numerous decentralized devices without exposing their privacy. However, due to the biased data distributions on involved devices, FL inherently suffers from low classification accuracy in non-IID scenarios. Although various device grouping method have been proposed to address this problem, most of them neglect both i) distinct data distribution characteristics of heterogeneous devices, and ii) contributions and hazards of local models, which are extremely important in determining the quality of global model aggregation. In this paper, we present an effective FL method named FedEntropy with a novel dynamic device grouping scheme, which makes full use of the above two factors based on our proposed maximum entropy judgement heuristic.Unlike existing FL methods that directly aggregate local models returned from all the selected devices, in one FL round FedEntropy firstly makes a judgement based on the pre-collected soft labels of selected devices and then only aggregates the local models that can maximize the overall entropy of these soft labels. Without collecting local models that are harmful for aggregation, FedEntropy can effectively improve global model accuracy while reducing the overall communication overhead. Comprehensive experimental results on well-known benchmarks show that, FedEntropy not only outperforms state-of-the-art FL methods in terms of model accuracy and communication overhead, but also can be integrated into them to enhance their classification performance. <|body|> FedEntropy: Efficient Device Grouping for Federated Learning Using Maximum Entropy Judgment <|EOS|>'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_dataset['validation'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos = '<|endoftext|>'\n",
    "eos = '<|EOS|>'\n",
    "pad = '<|pad|>'\n",
    "body = '<|body|>'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Title and Abstract. Add bos and eos tokens. Seperate title and abstract by body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    }
   ],
   "source": [
    "arxiv_dataset = arxiv_dataset.map(lambda x: {\"abstracttitle\": ' '.join([bos, x['abstract'], body, x['title'], eos]).replace(\"\\n\",\" \")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>   As an important problem in causal inference, we discuss the estimation of treatment effects (TEs). Representing the confounder as a latent variable, we propose Intact-VAE, a new variant of variational autoencoder (VAE), motivated by the prognostic score that is sufficient for identifying TEs. Our VAE also naturally gives representations balanced for treatment groups, using its prior. Experiments on (semi-)synthetic datasets show state-of-the-art performance under diverse settings, including unobserved confounding. Based on the identifiability of our model, we prove identification of TEs under unconfoundedness, and also discuss (possible) extensions to harder settings.  <|body|> Towards Principled Causal Effect Estimation by Deep Identifiable Models <|EOS|>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_dataset[\"train\"][\"abstracttitle\"][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get max length from dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sequence in train set has 512 words\n",
      "Longest sequence in val set has 327 words\n"
     ]
    }
   ],
   "source": [
    "train_max_length = find_max_length(arxiv_dataset[\"train\"][\"abstracttitle\"])\n",
    "val_max_length = find_max_length(arxiv_dataset[\"validation\"][\"abstracttitle\"])\n",
    "\n",
    "print(f\"Longest sequence in train set has {train_max_length} words\")\n",
    "print(f\"Longest sequence in val set has {val_max_length} words\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorboard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a44a7dfa71ff121c1b32add23bf472096244eb5361d8ac3b61007c87c3bb2ea6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
